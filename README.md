# Model Evaluation
<p align="center">
<a href="https://modelscope.cn/studios/AI-ModelScope/Evaluation-Model/summary"><img src="https://img.shields.io/badge/ModelScope-blueviolet" alt="modelscope"></a>
<a href="https://aistudio.baidu.com/aistudio/projectdetail/6145966"><img src="https://img.shields.io/badge/-AIStudio-337AFF" alt="AIStudio"></a>
</p> 

基于[ModelScope(魔搭)](https://modelscope.cn/studios/AI-ModelScope/Evaluation-Model/summary)社区和[飞桨AIStudio](https://aistudio.baidu.com/aistudio/projectdetail/6145966)社区, 依托平台巨大的用户规模, 通过开源模型推理或者API接入的方式, 探索为开发者提供针对LLM的测评体验. 其能够对于某个prompt基于不同的模型生成多个结果, 开发者能基于生成结果比较模型效果.

目前仍是雏形，还在系统规划当中，致力为中文大模型社区提供一个**机制尽可能公开透明**、**标准尽可能全面准确**、**结果尽可能真实权威**的大模型评价机制。

## 测评维度

| 模型名称 | 参数 | 研究单位 | 开源/API | 效果 |
|:----:| :----: | :----: | :----: | :----: |
| [ChatYuan-large-v2](https://github.com/clue-ai/ChatYuan) | 0.7B | 元语智能 | 开源 |  |
| [ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B) | 6B | [智谱·AI](https://maas.aminer.cn/) | 开源 |  |
| [MiniMax](https://api.minimax.chat/) | 未知 | [Minimax](https://api.minimax.chat/) | 否 | 好 |

## 参考资料
1. 聊天机器人竞技场排行榜： https://lmsys.org/blog
